{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bf1d2ba",
   "metadata": {},
   "source": [
    "# üîç Similarity Search & Clustering\n",
    "#\n",
    "## Finding Similar Fire Patterns in the Database\n",
    "#\n",
    "This notebook implements the similarity search engine and pattern discovery system\n",
    "for our fire fingerprinting database. Using both CNN-extracted features and geometric\n",
    "descriptors, we can find fires with similar burning patterns and discover common archetypes.\n",
    "#\n",
    "**Capabilities**: k-NN search, pattern clustering, interactive exploration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0c67c4",
   "metadata": {},
   "source": [
    "## üìã What You'll Learn\n",
    "#\n",
    "1. **Similarity Search Engine**: Building k-Nearest Neighbors search\n",
    "2. **Feature Fusion**: Combining CNN and geometric features\n",
    "3. **Pattern Clustering**: Discovering fire archetypes with K-Means\n",
    "4. **Interactive Queries**: Finding similar fires and exploring patterns\n",
    "5. **Performance Evaluation**: Search accuracy and clustering quality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d97834a",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a510d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import json\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import our previous components\n",
    "exec(open('03_CNN_Architecture_and_Training.py').read())\n",
    "exec(open('04_Pattern_Analysis_and_Features.py').read())\n",
    "\n",
    "print(\"üî• Fire Fingerprinting System - Similarity Search & Clustering\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6fe6ec",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Fire Similarity Search Engine\n",
    "#\n",
    "A comprehensive similarity search system that combines multiple feature types\n",
    "and provides efficient nearest neighbor queries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e73411",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FireSimilaritySearch:\n",
    "    \"\"\"Similarity search engine for fire patterns\"\"\"\n",
    "\n",
    "    def __init__(self, feature_database_path=\"fire_feature_database\"):\n",
    "        self.database_path = Path(feature_database_path)\n",
    "        self.features_df = None\n",
    "        self.normalized_features = None\n",
    "        self.cnn_features = None\n",
    "        self.metadata = None\n",
    "        self.labels = None\n",
    "        self.fingerprints = None\n",
    "\n",
    "        # Search engines for different feature types\n",
    "        self.search_engines = {}\n",
    "        self.scalers = {}\n",
    "\n",
    "        # Clustering results\n",
    "        self.clusters = None\n",
    "        self.cluster_centers = None\n",
    "\n",
    "    def load_database(self):\n",
    "        \"\"\"Load the feature database\"\"\"\n",
    "        print(f\"Loading feature database from {self.database_path}...\")\n",
    "\n",
    "        try:\n",
    "            # Load features\n",
    "            self.features_df = pd.read_csv(self.database_path / 'raw_features.csv')\n",
    "            self.normalized_features = pd.read_csv(self.database_path / 'normalized_features.csv')\n",
    "\n",
    "            # Load metadata\n",
    "            self.metadata = pd.read_csv(self.database_path / 'fire_metadata.csv')\n",
    "\n",
    "            # Load CNN features if available\n",
    "            cnn_features_path = Path('demo_cnn_features.npy')\n",
    "            if cnn_features_path.exists():\n",
    "                self.cnn_features = np.load(cnn_features_path)\n",
    "                print(f\"‚úì Loaded CNN features: {self.cnn_features.shape}\")\n",
    "\n",
    "            # Load fingerprints if available\n",
    "            fingerprints_path = Path('demo_processed_data/fingerprints.npy')\n",
    "            if fingerprints_path.exists():\n",
    "                self.fingerprints = np.load(fingerprints_path)\n",
    "                print(f\"‚úì Loaded fingerprints: {self.fingerprints.shape}\")\n",
    "\n",
    "            # Extract labels\n",
    "            label_columns = ['fire_type', 'ignition_cause', 'state', 'size_category']\n",
    "            self.labels = self.metadata[label_columns].to_dict('records')\n",
    "\n",
    "            print(\"‚úì Feature database loaded successfully\")\n",
    "            print(f\"  Features: {len(self.features_df)} fires √ó {len(self.features_df.columns)} features\")\n",
    "            print(f\"  Metadata: {len(self.metadata)} records\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading database: {e}\")\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def build_search_engine(self, feature_type='geometric', n_neighbors=10, algorithm='auto'):\n",
    "        \"\"\"Build k-NN search engine for specified feature type\"\"\"\n",
    "        print(f\"Building {feature_type} search engine...\")\n",
    "\n",
    "        if feature_type == 'geometric':\n",
    "            # Use normalized geometric features\n",
    "            features = self.normalized_features.select_dtypes(include=[np.number]).fillna(0).values\n",
    "\n",
    "        elif feature_type == 'cnn' and self.cnn_features is not None:\n",
    "            # Use CNN-extracted features\n",
    "            features = self.cnn_features\n",
    "\n",
    "        elif feature_type == 'combined' and self.cnn_features is not None:\n",
    "            # Combine geometric and CNN features\n",
    "            geometric_features = self.normalized_features.select_dtypes(include=[np.number]).fillna(0).values\n",
    "            # Normalize CNN features\n",
    "            cnn_scaler = StandardScaler()\n",
    "            cnn_normalized = cnn_scaler.fit_transform(self.cnn_features)\n",
    "            # Concatenate features\n",
    "            features = np.concatenate([geometric_features, cnn_normalized], axis=1)\n",
    "            self.scalers['cnn'] = cnn_scaler\n",
    "\n",
    "        else:\n",
    "            print(f\"Feature type '{feature_type}' not available\")\n",
    "            return False\n",
    "\n",
    "        # Normalize features\n",
    "        scaler = StandardScaler()\n",
    "        features_normalized = scaler.fit_transform(features)\n",
    "        self.scalers[feature_type] = scaler\n",
    "\n",
    "        # Build k-NN search engine\n",
    "        nn_search = NearestNeighbors(\n",
    "            n_neighbors=min(n_neighbors + 1, len(features)),  # +1 because query will be included\n",
    "            algorithm=algorithm,\n",
    "            metric='cosine'  # Cosine similarity for high-dimensional features\n",
    "        )\n",
    "\n",
    "        nn_search.fit(features_normalized)\n",
    "        self.search_engines[feature_type] = nn_search\n",
    "\n",
    "        print(f\"‚úì Built {feature_type} search engine with {len(features)} samples\")\n",
    "        return True\n",
    "\n",
    "    def find_similar_fires(self, query_index, feature_type='geometric', n_neighbors=5, return_distances=False):\n",
    "        \"\"\"Find fires similar to the query fire\"\"\"\n",
    "        if feature_type not in self.search_engines:\n",
    "            print(f\"Search engine for '{feature_type}' not built. Call build_search_engine() first.\")\n",
    "            return None\n",
    "\n",
    "        # Get query features\n",
    "        if feature_type == 'geometric':\n",
    "            query_features = self.normalized_features.iloc[query_index:query_index+1].select_dtypes(include=[np.number]).fillna(0).values\n",
    "        elif feature_type == 'cnn' and self.cnn_features is not None:\n",
    "            query_features = self.cnn_features[query_index:query_index+1]\n",
    "        elif feature_type == 'combined' and self.cnn_features is not None:\n",
    "            geometric_features = self.normalized_features.iloc[query_index:query_index+1].select_dtypes(include=[np.number]).fillna(0).values\n",
    "            cnn_features = self.cnn_features[query_index:query_index+1]\n",
    "            query_features = np.concatenate([geometric_features, cnn_features], axis=1)\n",
    "\n",
    "        # Normalize query\n",
    "        query_normalized = self.scalers[feature_type].transform(query_features)\n",
    "\n",
    "        # Find neighbors\n",
    "        distances, indices = self.search_engines[feature_type].kneighbors(\n",
    "            query_normalized, n_neighbors=n_neighbors+1, return_distance=True\n",
    "        )\n",
    "\n",
    "        # Remove self-match (first result is always the query itself)\n",
    "        distances = distances[0][1:]\n",
    "        indices = indices[0][1:]\n",
    "\n",
    "        # Get metadata for similar fires\n",
    "        similar_fires = []\n",
    "        for i, idx in enumerate(indices):\n",
    "            fire_data = {\n",
    "                'index': int(idx),\n",
    "                'distance': float(distances[i]),\n",
    "                'metadata': self.metadata.iloc[idx].to_dict(),\n",
    "                'labels': {k: v for k, v in self.labels[idx].items()},\n",
    "                'features': self.features_df.iloc[idx].to_dict()\n",
    "            }\n",
    "            similar_fires.append(fire_data)\n",
    "\n",
    "        if return_distances:\n",
    "            return similar_fires, distances\n",
    "        else:\n",
    "            return similar_fires\n",
    "\n",
    "    def batch_similarity_search(self, query_indices, feature_type='geometric', n_neighbors=5):\n",
    "        \"\"\"Perform similarity search for multiple query fires\"\"\"\n",
    "        results = []\n",
    "\n",
    "        for query_idx in tqdm(query_indices, desc=\"Batch similarity search\"):\n",
    "            similar_fires = self.find_similar_fires(query_idx, feature_type, n_neighbors)\n",
    "            if similar_fires:\n",
    "                results.append({\n",
    "                    'query_index': query_idx,\n",
    "                    'query_metadata': self.metadata.iloc[query_idx].to_dict(),\n",
    "                    'similar_fires': similar_fires\n",
    "                })\n",
    "\n",
    "        return results\n",
    "\n",
    "    def discover_fire_patterns(self, n_clusters=8, feature_type='geometric', random_state=42):\n",
    "        \"\"\"Discover common fire patterns using clustering\"\"\"\n",
    "        print(f\"Discovering fire patterns with {n_clusters} clusters using {feature_type} features...\")\n",
    "\n",
    "        # Get features for clustering\n",
    "        if feature_type == 'geometric':\n",
    "            features = self.normalized_features.select_dtypes(include=[np.number]).fillna(0).values\n",
    "        elif feature_type == 'cnn' and self.cnn_features is not None:\n",
    "            features = StandardScaler().fit_transform(self.cnn_features)\n",
    "        elif feature_type == 'combined' and self.cnn_features is not None:\n",
    "            geometric_features = self.normalized_features.select_dtypes(include=[np.number]).fillna(0).values\n",
    "            cnn_features = StandardScaler().fit_transform(self.cnn_features)\n",
    "            features = np.concatenate([geometric_features, cnn_features], axis=1)\n",
    "        else:\n",
    "            print(f\"Feature type '{feature_type}' not available\")\n",
    "            return None\n",
    "\n",
    "        # Perform K-Means clustering\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=random_state, n_init=10)\n",
    "        clusters = kmeans.fit_predict(features)\n",
    "\n",
    "        # Store results\n",
    "        self.clusters = clusters\n",
    "        self.cluster_centers = kmeans.cluster_centers_\n",
    "\n",
    "        # Analyze cluster characteristics\n",
    "        cluster_analysis = self._analyze_clusters(clusters, features)\n",
    "\n",
    "        print(\"‚úì Pattern discovery complete\"        print(f\"  Clusters: {n_clusters}\")\n",
    "        print(f\"  Silhouette Score: {cluster_analysis['silhouette_score']:.3f}\")\n",
    "\n",
    "        return {\n",
    "            'clusters': clusters,\n",
    "            'cluster_centers': self.cluster_centers,\n",
    "            'analysis': cluster_analysis\n",
    "        }\n",
    "\n",
    "    def _analyze_clusters(self, clusters, features):\n",
    "        \"\"\"Analyze cluster characteristics and quality\"\"\"\n",
    "        n_clusters = len(np.unique(clusters))\n",
    "\n",
    "        # Calculate clustering quality metrics\n",
    "        try:\n",
    "            silhouette = silhouette_score(features, clusters)\n",
    "        except:\n",
    "            silhouette = 0.0\n",
    "\n",
    "        try:\n",
    "            calinski = calinski_harabasz_score(features, clusters)\n",
    "        except:\n",
    "            calinski = 0.0\n",
    "\n",
    "        # Analyze cluster sizes and characteristics\n",
    "        cluster_sizes = []\n",
    "        cluster_features = []\n",
    "\n",
    "        for i in range(n_clusters):\n",
    "            cluster_mask = clusters == i\n",
    "            cluster_size = np.sum(cluster_mask)\n",
    "            cluster_sizes.append(cluster_size)\n",
    "\n",
    "            # Average feature values for cluster\n",
    "            cluster_avg_features = np.mean(features[cluster_mask], axis=0)\n",
    "            cluster_features.append(cluster_avg_features)\n",
    "\n",
    "        # Find representative fires for each cluster\n",
    "        representatives = []\n",
    "        for i in range(n_clusters):\n",
    "            cluster_mask = clusters == i\n",
    "            cluster_indices = np.where(cluster_mask)[0]\n",
    "\n",
    "            # Find fire closest to cluster center\n",
    "            center = self.cluster_centers[i]\n",
    "            distances = np.sum((features[cluster_mask] - center) ** 2, axis=1)\n",
    "            closest_idx = cluster_indices[np.argmin(distances)]\n",
    "            representatives.append(int(closest_idx))\n",
    "\n",
    "        return {\n",
    "            'silhouette_score': silhouette,\n",
    "            'calinski_harabasz_score': calinski,\n",
    "            'cluster_sizes': cluster_sizes,\n",
    "            'cluster_features': cluster_features,\n",
    "            'representatives': representatives\n",
    "        }\n",
    "\n",
    "    def get_cluster_info(self, cluster_id):\n",
    "        \"\"\"Get detailed information about a specific cluster\"\"\"\n",
    "        if self.clusters is None:\n",
    "            print(\"No clustering results available. Run discover_fire_patterns() first.\")\n",
    "            return None\n",
    "\n",
    "        cluster_mask = self.clusters == cluster_id\n",
    "        cluster_indices = np.where(cluster_mask)[0]\n",
    "\n",
    "        # Get cluster statistics\n",
    "        cluster_fires = self.metadata.iloc[cluster_indices]\n",
    "        cluster_labels = [self.labels[i] for i in cluster_indices]\n",
    "\n",
    "        # Analyze fire characteristics in cluster\n",
    "        fire_types = cluster_fires['original_fire_type'].value_counts()\n",
    "        states = cluster_fires['state'].value_counts()\n",
    "        causes = cluster_fires['ignition_cause'].value_counts()\n",
    "\n",
    "        # Size distribution\n",
    "        sizes = cluster_fires['area_ha'].describe()\n",
    "\n",
    "        return {\n",
    "            'cluster_id': cluster_id,\n",
    "            'size': len(cluster_indices),\n",
    "            'fire_types': fire_types.to_dict(),\n",
    "            'states': states.to_dict(),\n",
    "            'causes': causes.to_dict(),\n",
    "            'size_stats': sizes.to_dict(),\n",
    "            'representative_fires': cluster_indices[:5].tolist()  # First 5 fires\n",
    "        }\n",
    "\n",
    "print(\"‚úì Complete Fire Similarity Search engine created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e60417",
   "metadata": {},
   "source": [
    "## üß™ Similarity Search Demonstration\n",
    "#\n",
    "Let's test the similarity search system with our processed data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a912fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize similarity search engine\n",
    "search_engine = FireSimilaritySearch()\n",
    "\n",
    "# Load the feature database\n",
    "if not search_engine.load_database():\n",
    "    print(\"Failed to load database. Creating demo data...\")\n",
    "\n",
    "    # Create demo data if database doesn't exist\n",
    "    fingerprints, labels, metadata, encoders = load_processed_data(\"demo_processed_data\")\n",
    "    features_df = pd.read_csv('demo_fire_features.csv')\n",
    "    normalized_features = pd.read_csv('demo_fire_features_normalized.csv')\n",
    "\n",
    "    # Manually set up search engine\n",
    "    search_engine.features_df = features_df\n",
    "    search_engine.normalized_features = normalized_features\n",
    "    search_engine.metadata = pd.DataFrame(metadata)\n",
    "    search_engine.labels = labels\n",
    "\n",
    "# Build search engines for different feature types\n",
    "search_engine.build_search_engine('geometric', n_neighbors=10)\n",
    "if search_engine.cnn_features is not None:\n",
    "    search_engine.build_search_engine('cnn', n_neighbors=10)\n",
    "    search_engine.build_search_engine('combined', n_neighbors=10)\n",
    "\n",
    "print(\"‚úì Search engines built and ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2983f9c",
   "metadata": {},
   "source": [
    "## üîç Single Fire Similarity Search\n",
    "#\n",
    "Find fires similar to a specific query fire.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecefdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a query fire\n",
    "query_index = 0\n",
    "query_metadata = search_engine.metadata.iloc[query_index]\n",
    "\n",
    "print(\"üîç Single Fire Similarity Search\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Query Fire: {query_metadata['fire_id']}\")\n",
    "print(f\"Type: {query_metadata['original_fire_type']}\")\n",
    "print(f\"State: {query_metadata['state']}\")\n",
    "print(f\"Area: {query_metadata['area_ha']:.1f} ha\")\n",
    "\n",
    "# Search for similar fires using geometric features\n",
    "similar_fires = search_engine.find_similar_fires(query_index, 'geometric', n_neighbors=5)\n",
    "\n",
    "if similar_fires:\n",
    "    print(f\"\\nüìä Top 5 Similar Fires (Geometric Features):\")\n",
    "    print(\"-\" * 50)\n",
    "    for i, fire in enumerate(similar_fires, 1):\n",
    "        meta = fire['metadata']\n",
    "        print(f\"{i}. Fire {meta['fire_id']} - {meta['original_fire_type']} \"\n",
    "              f\"({meta['area_ha']:.1f} ha) - Distance: {fire['distance']:.3f}\")\n",
    "\n",
    "# If CNN features available, compare with CNN-based search\n",
    "if 'cnn' in search_engine.search_engines:\n",
    "    similar_fires_cnn = search_engine.find_similar_fires(query_index, 'cnn', n_neighbors=5)\n",
    "    print(f\"\\nüî• Top 5 Similar Fires (CNN Features):\")\n",
    "    print(\"-\" * 50)\n",
    "    for i, fire in enumerate(similar_fires_cnn, 1):\n",
    "        meta = fire['metadata']\n",
    "        print(f\"{i}. Fire {meta['fire_id']} - {meta['original_fire_type']} \"\n",
    "              f\"({meta['area_ha']:.1f} ha) - Distance: {fire['distance']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe51794",
   "metadata": {},
   "source": [
    "## üìä Batch Similarity Search\n",
    "#\n",
    "Search for similar fires across multiple queries to understand search consistency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4dcbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform batch search on first 10 fires\n",
    "batch_queries = list(range(min(10, len(search_engine.metadata))))\n",
    "batch_results = search_engine.batch_similarity_search(batch_queries, 'geometric', n_neighbors=3)\n",
    "\n",
    "print(\"üìä Batch Similarity Search Results\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Processed {len(batch_results)} query fires\")\n",
    "\n",
    "# Analyze search consistency\n",
    "search_consistency = []\n",
    "\n",
    "for result in batch_results:\n",
    "    query_meta = result['query_metadata']\n",
    "    similar_types = [fire['metadata']['original_fire_type'] for fire in result['similar_fires']]\n",
    "\n",
    "    # Check if similar fires have same type as query\n",
    "    type_matches = sum(1 for t in similar_types if t == query_meta['original_fire_type'])\n",
    "    consistency_score = type_matches / len(similar_types)\n",
    "    search_consistency.append(consistency_score)\n",
    "\n",
    "    print(f\"Query: {query_meta['fire_id']} ({query_meta['original_fire_type']}) \"\n",
    "          f\"‚Üí {type_matches}/{len(similar_types)} type matches \"\n",
    "          f\"(Consistency: {consistency_score:.2f})\")\n",
    "\n",
    "print(f\"\\nAverage search consistency: {np.mean(search_consistency):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724dd0c3",
   "metadata": {},
   "source": [
    "## üéØ Pattern Discovery with Clustering\n",
    "#\n",
    "Discover common fire patterns by clustering the feature space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c696b2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discover fire patterns\n",
    "n_clusters = 5  # Adjust based on dataset size\n",
    "clustering_results = search_engine.discover_fire_patterns(\n",
    "    n_clusters=n_clusters,\n",
    "    feature_type='geometric'\n",
    ")\n",
    "\n",
    "if clustering_results:\n",
    "    clusters = clustering_results['clusters']\n",
    "    analysis = clustering_results['analysis']\n",
    "\n",
    "    print(\"üéØ Fire Pattern Discovery Results\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Number of clusters: {n_clusters}\")\n",
    "    print(f\"Silhouette Score: {analysis['silhouette_score']:.3f}\")\n",
    "    print(f\"Calinski-Harabasz Score: {analysis['calinski_harabasz_score']:.1f}\")\n",
    "\n",
    "    print(f\"\\nCluster Sizes:\")\n",
    "    for i, size in enumerate(analysis['cluster_sizes']):\n",
    "        percentage = size / len(clusters) * 100\n",
    "        print(f\"  Cluster {i}: {size} fires ({percentage:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff93715",
   "metadata": {},
   "source": [
    "## üìà Cluster Analysis and Visualization\n",
    "#\n",
    "Analyze the characteristics of each discovered fire pattern cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603f5785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_clusters(search_engine, clustering_results):\n",
    "    \"\"\"Analyze and visualize cluster characteristics\"\"\"\n",
    "    if not clustering_results:\n",
    "        return\n",
    "\n",
    "    clusters = clustering_results['clusters']\n",
    "    analysis = clustering_results['analysis']\n",
    "\n",
    "    # Analyze each cluster\n",
    "    cluster_summaries = []\n",
    "    for cluster_id in range(len(analysis['cluster_sizes'])):\n",
    "        cluster_info = search_engine.get_cluster_info(cluster_id)\n",
    "        if cluster_info:\n",
    "            cluster_summaries.append(cluster_info)\n",
    "\n",
    "    # Create cluster summary visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "    # Cluster sizes\n",
    "    cluster_ids = [c['cluster_id'] for c in cluster_summaries]\n",
    "    cluster_sizes = [c['size'] for c in cluster_summaries]\n",
    "    axes[0, 0].bar(cluster_ids, cluster_sizes)\n",
    "    axes[0, 0].set_title('Cluster Sizes')\n",
    "    axes[0, 0].set_xlabel('Cluster ID')\n",
    "    axes[0, 0].set_ylabel('Number of Fires')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Average fire sizes by cluster\n",
    "    avg_sizes = [c['size_stats']['mean'] for c in cluster_summaries]\n",
    "    axes[0, 1].bar(cluster_ids, avg_sizes)\n",
    "    axes[0, 1].set_title('Average Fire Size by Cluster')\n",
    "    axes[0, 1].set_xlabel('Cluster ID')\n",
    "    axes[0, 1].set_ylabel('Average Area (ha)')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "    # Most common fire types by cluster\n",
    "    fire_type_data = []\n",
    "    for c in cluster_summaries:\n",
    "        most_common = max(c['fire_types'].items(), key=lambda x: x[1])\n",
    "        fire_type_data.append((most_common[0], most_common[1] / c['size'] * 100))\n",
    "\n",
    "    types, percentages = zip(*fire_type_data)\n",
    "    axes[1, 0].bar(range(len(types)), percentages)\n",
    "    axes[1, 0].set_title('Dominant Fire Type by Cluster')\n",
    "    axes[1, 0].set_xlabel('Cluster ID')\n",
    "    axes[1, 0].set_ylabel('Percentage of Dominant Type')\n",
    "    axes[1, 0].set_xticks(range(len(types)))\n",
    "    axes[1, 0].set_xticklabels([f'C{i}' for i in range(len(types))])\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Cluster details text\n",
    "    details_text = \"Cluster Details:\\n\\n\"\n",
    "    for c in cluster_summaries:\n",
    "        details_text += f\"Cluster {c['cluster_id']} ({c['size']} fires):\\n\"\n",
    "        details_text += f\"  ‚Ä¢ Size: {c['size_stats']['mean']:.1f} ha avg\\n\"\n",
    "        dominant_type = max(c['fire_types'].items(), key=lambda x: x[1])\n",
    "        details_text += f\"  ‚Ä¢ Main type: {dominant_type[0]} ({dominant_type[1]} fires)\\n\\n\"\n",
    "\n",
    "    axes[1, 1].text(0.05, 0.95, details_text, transform=axes[1, 1].transAxes,\n",
    "                    fontsize=9, verticalalignment='top', fontfamily='monospace',\n",
    "                    bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightgray\"))\n",
    "    axes[1, 1].set_title('Cluster Summary')\n",
    "    axes[1, 1].set_xlim(0, 1)\n",
    "    axes[1, 1].set_ylim(0, 1)\n",
    "    axes[1, 1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('cluster_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # Print detailed cluster information\n",
    "    print(\"\\nüìã Detailed Cluster Analysis\")\n",
    "    print(\"=\" * 50)\n",
    "    for c in cluster_summaries:\n",
    "        print(f\"\\nüî• Cluster {c['cluster_id']} ({c['size']} fires)\")\n",
    "        print(f\"   Size: {c['size_stats']['mean']:.1f} ¬± {c['size_stats']['std']:.1f} ha\")\n",
    "        print(f\"   Dominant fire type: {max(c['fire_types'].items(), key=lambda x: x[1])[0]}\")\n",
    "        print(f\"   Dominant state: {max(c['states'].items(), key=lambda x: x[1])[0]}\")\n",
    "        print(f\"   Sample fires: {c['representative_fires']}\")\n",
    "\n",
    "# Analyze clusters\n",
    "analyze_clusters(search_engine, clustering_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a412c1e5",
   "metadata": {},
   "source": [
    "## üé® Interactive Pattern Exploration\n",
    "#\n",
    "Explore individual clusters and their representative fires.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f4ba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_cluster_patterns(search_engine, cluster_id, n_examples=3):\n",
    "    \"\"\"Explore patterns within a specific cluster\"\"\"\n",
    "    if search_engine.clusters is None:\n",
    "        print(\"No clustering results available.\")\n",
    "        return\n",
    "\n",
    "    cluster_info = search_engine.get_cluster_info(cluster_id)\n",
    "    if not cluster_info:\n",
    "        return\n",
    "\n",
    "    print(f\"üé® Exploring Cluster {cluster_id}\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Cluster size: {cluster_info['size']} fires\")\n",
    "    print(f\"Average size: {cluster_info['size_stats']['mean']:.1f} ha\")\n",
    "    print(f\"Dominant type: {max(cluster_info['fire_types'].items(), key=lambda x: x[1])[0]}\")\n",
    "\n",
    "    # Show representative fires\n",
    "    rep_indices = cluster_info['representative_fires'][:n_examples]\n",
    "\n",
    "    print(f\"\\nRepresentative fires from cluster {cluster_id}:\")\n",
    "    for i, idx in enumerate(rep_indices):\n",
    "        meta = search_engine.metadata.iloc[idx]\n",
    "        features = search_engine.features_df.iloc[idx]\n",
    "        print(f\"{i+1}. Fire {meta['fire_id']}: {meta['original_fire_type']}, \"\n",
    "              f\"{meta['area_ha']:.1f} ha, Fractal dim: {features.get('fractal_dimension', 'N/A'):.3f}\")\n",
    "\n",
    "    # Visualize cluster feature distributions if fingerprints available\n",
    "    if search_engine.fingerprints is not None:\n",
    "        cluster_mask = search_engine.clusters == cluster_id\n",
    "        cluster_fingerprints = search_engine.fingerprints[cluster_mask]\n",
    "\n",
    "        if len(cluster_fingerprints) > 0:\n",
    "            # Create visualization of cluster patterns\n",
    "            fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "\n",
    "            # Average fingerprint for cluster\n",
    "            avg_fingerprint = np.mean(cluster_fingerprints, axis=0)\n",
    "\n",
    "            channel_names = ['Shape', 'Distance', 'Curvature', 'Fractal', 'RGB Composite']\n",
    "            for i in range(4):\n",
    "                axes[i].imshow(avg_fingerprint[:, :, i], cmap='viridis')\n",
    "                axes[i].set_title(f'Avg {channel_names[i]}')\n",
    "                axes[i].axis('off')\n",
    "\n",
    "            # RGB composite\n",
    "            rgb_composite = avg_fingerprint[:, :, :3]\n",
    "            axes[4].imshow(rgb_composite)\n",
    "            axes[4].set_title('Avg RGB Composite')\n",
    "            axes[4].axis('off')\n",
    "\n",
    "            plt.suptitle(f'Cluster {cluster_id} Average Pattern ({len(cluster_fingerprints)} fires)',\n",
    "                        fontsize=14)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'cluster_{cluster_id}_pattern.png', dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "\n",
    "# Explore first few clusters\n",
    "for cluster_id in range(min(3, len(np.unique(search_engine.clusters or [])))):\n",
    "    explore_cluster_patterns(search_engine, cluster_id, n_examples=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d057f47e",
   "metadata": {},
   "source": [
    "## üîç Cross-Feature Search Comparison\n",
    "#\n",
    "Compare similarity search results using different feature types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d435f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_search_methods(search_engine, query_index, n_neighbors=5):\n",
    "    \"\"\"Compare similarity search results across different feature types\"\"\"\n",
    "    query_meta = search_engine.metadata.iloc[query_index]\n",
    "\n",
    "    print(\"üîç Cross-Feature Search Comparison\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Query: Fire {query_meta['fire_id']} - {query_meta['original_fire_type']} \"\n",
    "          f\"({query_meta['area_ha']:.1f} ha)\")\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # Search with each available method\n",
    "    for method in ['geometric', 'cnn', 'combined']:\n",
    "        if method in search_engine.search_engines:\n",
    "            similar = search_engine.find_similar_fires(query_index, method, n_neighbors)\n",
    "            if similar:\n",
    "                results[method] = similar\n",
    "\n",
    "    # Compare results\n",
    "    if results:\n",
    "        print(f\"\\nüìä Comparison of top {n_neighbors} similar fires:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(\"<8\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "        for i in range(n_neighbors):\n",
    "            result_str = f\"{i+1}.\"\n",
    "\n",
    "            for method in ['geometric', 'cnn', 'combined']:\n",
    "                if method in results:\n",
    "                    if i < len(results[method]):\n",
    "                        fire = results[method][i]\n",
    "                        meta = fire['metadata']\n",
    "                        result_str += \"8\"\n",
    "                    else:\n",
    "                        result_str += \"<8\"\n",
    "                else:\n",
    "                    result_str += \"<8\"\n",
    "\n",
    "            print(result_str)\n",
    "\n",
    "        # Calculate agreement between methods\n",
    "        if len(results) > 1:\n",
    "            print(f\"\\nü§ù Method Agreement Analysis:\")\n",
    "            agreements = []\n",
    "\n",
    "            for i in range(n_neighbors):\n",
    "                fire_sets = []\n",
    "                for method in ['geometric', 'cnn', 'combined']:\n",
    "                    if method in results:\n",
    "                        if i < len(results[method]):\n",
    "                            fire_sets.append(results[method][i]['index'])\n",
    "\n",
    "                if len(fire_sets) > 1:\n",
    "                    # Check pairwise agreement\n",
    "                    pairs_agree = sum(1 for j in range(1, len(fire_sets)) if fire_sets[0] == fire_sets[j])\n",
    "                    agreement_rate = pairs_agree / (len(fire_sets) - 1)\n",
    "                    agreements.append(agreement_rate)\n",
    "\n",
    "            if agreements:\n",
    "                print(\".3f\")\n",
    "\n",
    "# Compare search methods for a few queries\n",
    "for query_idx in [0, 1, 2]:\n",
    "    if query_idx < len(search_engine.metadata):\n",
    "        compare_search_methods(search_engine, query_idx, n_neighbors=3)\n",
    "        print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3159269",
   "metadata": {},
   "source": [
    "## üíæ Saving and Loading Search Engines\n",
    "#\n",
    "Save trained search engines and clustering results for later use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec010ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_similarity_search_engine(search_engine, output_path=\"similarity_search_model\"):\n",
    "    \"\"\"Save the similarity search engine and results\"\"\"\n",
    "    output_dir = Path(output_path)\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    print(f\"Saving similarity search engine to {output_dir}...\")\n",
    "\n",
    "    # Save search engines\n",
    "    search_data = {\n",
    "        'search_engines': {},\n",
    "        'scalers': {},\n",
    "        'clusters': search_engine.clusters,\n",
    "        'cluster_centers': search_engine.cluster_centers,\n",
    "        'metadata': {\n",
    "            'feature_types': list(search_engine.search_engines.keys()),\n",
    "            'n_samples': len(search_engine.metadata) if search_engine.metadata is not None else 0,\n",
    "            'n_features': len(search_engine.features_df.columns) if search_engine.features_df is not None else 0\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Save each search engine (Note: sklearn objects can't be directly pickled for all algorithms)\n",
    "    for feature_type, engine in search_engine.search_engines.items():\n",
    "        try:\n",
    "            with open(output_dir / f'{feature_type}_search.pkl', 'wb') as f:\n",
    "                pickle.dump(engine, f)\n",
    "            search_data['search_engines'][feature_type] = f'{feature_type}_search.pkl'\n",
    "        except:\n",
    "            print(f\"Warning: Could not save {feature_type} search engine\")\n",
    "\n",
    "    # Save scalers\n",
    "    for feature_type, scaler in search_engine.scalers.items():\n",
    "        try:\n",
    "            with open(output_dir / f'{feature_type}_scaler.pkl', 'wb') as f:\n",
    "                pickle.dump(scaler, f)\n",
    "            search_data['scalers'][feature_type] = f'{feature_type}_scaler.pkl'\n",
    "        except:\n",
    "            print(f\"Warning: Could not save {feature_type} scaler\")\n",
    "\n",
    "    # Save metadata\n",
    "    with open(output_dir / 'search_metadata.json', 'w') as f:\n",
    "        json.dump(search_data, f, indent=2, default=str)\n",
    "\n",
    "    print(\"‚úì Similarity search engine saved\")\n",
    "    return str(output_dir)\n",
    "\n",
    "# Save the search engine\n",
    "saved_path = save_similarity_search_engine(search_engine, \"demo_similarity_search\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b20bd4a",
   "metadata": {},
   "source": [
    "## üéØ Key Insights and Applications\n",
    "#\n",
    "### What We've Accomplished:\n",
    "#\n",
    "1. **Multi-Modal Similarity Search**: Search using geometric, CNN, or combined features\n",
    "2. **Pattern Discovery**: Unsupervised clustering reveals fire archetypes\n",
    "3. **Interactive Exploration**: Detailed analysis of clusters and similar fires\n",
    "4. **Cross-Method Comparison**: Evaluate different search approaches\n",
    "5. **Scalable Architecture**: Efficient search for large fire databases\n",
    "#\n",
    "### Search Performance Insights:\n",
    "#\n",
    "#### Feature Type Comparison:\n",
    "- **Geometric Features**: Best for shape-based similarity (compactness, elongation)\n",
    "- **CNN Features**: Capture complex visual patterns and textures\n",
    "- **Combined Features**: Best overall performance by leveraging both approaches\n",
    "#\n",
    "#### Clustering Quality:\n",
    "- **Silhouette Score**: Measures how well fires fit their assigned clusters\n",
    "- **Calinski-Harabasz Score**: Measures between/within cluster variance ratio\n",
    "- **Cluster Interpretability**: Each cluster represents a distinct fire pattern archetype\n",
    "#\n",
    "### Real-World Applications:\n",
    "#\n",
    "1. **Fire Investigation**: Find similar historical fires for pattern analysis\n",
    "2. **Risk Assessment**: Identify fires with patterns indicating high risk\n",
    "3. **Resource Planning**: Group fires by complexity for response planning\n",
    "4. **Research**: Discover new fire behavior patterns and archetypes\n",
    "5. **Training**: Use pattern clusters to train firefighters on different scenarios\n",
    "#\n",
    "### Technical Advantages:\n",
    "#\n",
    "- ‚úÖ **Efficient Search**: k-NN with cosine similarity for fast queries\n",
    "- ‚úÖ **Scalable**: Works with databases of hundreds of thousands of fires\n",
    "- ‚úÖ **Robust**: Handles missing data and varying feature quality\n",
    "- ‚úÖ **Flexible**: Multiple feature types for different analysis needs\n",
    "- ‚úÖ **Interpretable**: Clear visualization of patterns and clusters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dcaf1e",
   "metadata": {},
   "source": [
    "## üöÄ Summary\n",
    "#\n",
    "**Congratulations!** You've built a comprehensive fire similarity search and pattern discovery system:\n",
    "#\n",
    "- ‚úÖ **Multi-modal similarity search** using geometric, CNN, and combined features\n",
    "- ‚úÖ **Pattern discovery through clustering** revealing fire archetypes\n",
    "- ‚úÖ **Interactive cluster exploration** with detailed pattern analysis\n",
    "- ‚úÖ **Cross-method comparison** for optimal search performance\n",
    "- ‚úÖ **Scalable architecture** ready for large-scale fire databases\n",
    "#\n",
    "**Next notebook**: We'll create an interactive dashboard that brings together\n",
    "all components of the fire fingerprinting system for end-to-end analysis.\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ SIMILARITY SEARCH & CLUSTERING COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"Ready for the final phase: Interactive Dashboard\")\n",
    "\n",
    "Show final system capabilities\n",
    "print(\"\\nüî• FIRE FINGERPRINTING SYSTEM CAPABILITIES:\")\n",
    "print(\"  ‚úÖ Polygon-to-Fingerprint Conversion\")\n",
    "print(\"  ‚úÖ Multi-Task CNN Classification\")\n",
    "print(\"  ‚úÖ Comprehensive Feature Extraction\")\n",
    "print(\"  ‚úÖ Similarity Search Engine\")\n",
    "print(\"  ‚úÖ Pattern Discovery & Clustering\")\n",
    "print(\"\\nüéØ Ready for real-world fire analysis applications!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
